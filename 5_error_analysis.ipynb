{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd861791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_icd_codes_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Read ICD codes from a text file where each line contains an ICD code followed by a description.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): The path to the text file containing the ICD codes and descriptions.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of ICD codes extracted from the file.\n",
    "    \"\"\"\n",
    "    icd_codes = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            code = line.split()[0]  # Assumes that the code and description are separated by whitespace\n",
    "            icd_codes.append(code)\n",
    "    \n",
    "    return icd_codes\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/Users/houzhen/research/LLMCoder/ALLcode/ICD-10/icd10cm-codes-2025.txt'\n",
    "icd_codes = read_icd_codes_from_file(file_path)\n",
    "print(icd_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844649c2",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b78f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def calculate_existence_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    \n",
    "    predict_col = 'predict' if 'predict' in df.columns else 'generated_result'\n",
    "    label_col = 'label' if 'label' in df.columns else 'ground_truth'\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row[label_col]))\n",
    "            pred_codes = set(extract_icd_codes(row[predict_col]))\n",
    "            \n",
    "            total_predictions += len(pred_codes)\n",
    "            \n",
    "            invalid_codes = [code for code in pred_codes if code not in icd_codes]\n",
    "            if invalid_codes:\n",
    "                error_rows += 1\n",
    "                invalid_predictions += len(invalid_codes)\n",
    "    else:\n",
    "        # Compare only the first prediction and the first label\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row[label_col])\n",
    "            pred_codes = extract_icd_codes(row[predict_col])\n",
    "            \n",
    "            if true_codes and pred_codes:\n",
    "                \n",
    "                if pred_codes[0] not in icd_codes:\n",
    "                    error_rows += 1\n",
    "                    invalid_predictions += 1\n",
    "    \n",
    "    error_rate = error_rows / total_rows if total_rows > 0 else 0\n",
    "    invalid_rate = invalid_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': total_rows,\n",
    "        'error_samples': error_rows,\n",
    "        'error_rate': error_rate,\n",
    "        'total_predictions': total_predictions,\n",
    "        'invalid_predictions': invalid_predictions,\n",
    "        'invalid_rate': invalid_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder, icd_codes):\n",
    "    \"\"\"Analyze all files in the folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # CSV file\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "            for filename in csv_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = 'multi' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_existence_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total samples: {error_stats['total_samples']}\")\n",
    "                    print(f\"Error samples: {error_stats['error_samples']}\")\n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Invalid predictions: {error_stats['invalid_predictions']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    print(f\"Invalid prediction rate: {error_stats['invalid_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "                        if len(df) > 0:\n",
    "                            print(\"Example of the first row:\")\n",
    "                            print(df.iloc[0])\n",
    "            \n",
    "            # JSONL file\n",
    "    \n",
    "    return results\n",
    "\n",
    "# function unchanged\n",
    "\n",
    "folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/challange/auto/GPT\"\n",
    "]\n",
    "\n",
    "print(\"Collecting valid ICD codes...\")\n",
    "valid_icd_codes = collect_valid_codes(folders)\n",
    "print(f\"Collected {len(valid_icd_codes)} valid ICD codes\")\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\nProcessing fileå¤¹: {folder}\")\n",
    "    results = analyze_files(folder, valid_icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'existence_errors_{os.path.basename(folder)}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(\"\\n=== Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72258439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    \"\"\"Determine if there is a hierarchical error between two codes\"\"\"\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def calculate_level_errors(df, is_multi=False):\n",
    "    \"\"\"Calculate hierarchical errors\"\"\"\n",
    "    total_predictions = 0\n",
    "    level_errors = 0\n",
    "    \n",
    "    predict_col = 'predict' if 'predict' in df.columns else 'generated_result'\n",
    "    label_col = 'label' if 'label' in df.columns else 'ground_truth'\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row[label_col]))\n",
    "            pred_codes = set(extract_icd_codes(row[predict_col]))\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                total_predictions += 1\n",
    "                if any(is_level_error(true_code, pred_code) for true_code in true_codes):\n",
    "                    level_errors += 1\n",
    "    else:\n",
    "        # Compare only the first prediction and the first label\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row[label_col])\n",
    "            pred_codes = extract_icd_codes(row[predict_col])\n",
    "            \n",
    "                total_predictions += 1\n",
    "                if is_level_error(true_codes[0], pred_codes[0]):\n",
    "                    level_errors += 1\n",
    "    \n",
    "    error_rate = level_errors / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_predictions': total_predictions,\n",
    "        'level_errors': level_errors,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder):\n",
    "    \"\"\"Analyze all files in the folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # CSV file\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "            for filename in csv_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = 'multi' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_level_errors(df, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Hierarchical errors: {error_stats['level_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "                        if len(df) > 0:\n",
    "                            print(\"Example of the first row:\")\n",
    "                            print(df.iloc[0])\n",
    "            \n",
    "            # JSONL file\n",
    "            jsonl_files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl') and 'trainer_log' not in f]\n",
    "            for filename in jsonl_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_level_errors(df, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Hierarchical errors: {error_stats['level_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "                        if len(df) > 0:\n",
    "                            print(\"Example of the first row:\")\n",
    "                            print(df.iloc[0])\n",
    "    \n",
    "    return results\n",
    "\n",
    "folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/challange/auto/GPT\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\nProcessing fileå¤¹: {folder}\")\n",
    "    results = analyze_files(folder)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'level_errors_{os.path.basename(folder)}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(\"\\n=== Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631da31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    \"\"\"Determine if there is a hierarchical error between two codes\"\"\"\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def is_character_error(true_code, pred_code, icd_codes):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    # ICD code\n",
    "    if pred_code not in icd_codes:\n",
    "        return False\n",
    "        \n",
    "    if is_level_error(true_code, pred_code):\n",
    "        return False\n",
    "    \n",
    "    true_match = re.match(r'([A-Z])(\\d+.*)', true_code)\n",
    "    pred_match = re.match(r'([A-Z])(\\d+.*)', pred_code)\n",
    "    \n",
    "    if true_match and pred_match:\n",
    "        true_letter, true_nums = true_match.groups()\n",
    "        pred_letter, pred_nums = pred_match.groups()\n",
    "        \n",
    "        if true_letter == pred_letter and true_code != pred_code:\n",
    "            if len(true_code) == len(pred_code):\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def calculate_character_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    total_predictions = 0\n",
    "    char_errors = 0\n",
    "    \n",
    "    predict_col = 'predict' if 'predict' in df.columns else 'generated_result'\n",
    "    label_col = 'label' if 'label' in df.columns else 'ground_truth'\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row[label_col]))\n",
    "            pred_codes = set(extract_icd_codes(row[predict_col]))\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                    total_predictions += 1\n",
    "                    if any(true_code and is_character_error(true_code, pred_code, icd_codes) \n",
    "                          for true_code in true_codes):\n",
    "                        char_errors += 1\n",
    "    else:\n",
    "        # Compare only the first prediction and the first label\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row[label_col])\n",
    "            pred_codes = extract_icd_codes(row[predict_col])\n",
    "            \n",
    "                true_code = true_codes[0]\n",
    "                pred_code = pred_codes[0]\n",
    "                \n",
    "                    total_predictions += 1\n",
    "                    if is_character_error(true_code, pred_code, icd_codes):\n",
    "                        char_errors += 1\n",
    "    \n",
    "    error_rate = char_errors / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_predictions': total_predictions,\n",
    "        'character_errors': char_errors,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder, icd_codes):\n",
    "    \"\"\"Analyze all files in the folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # CSV file\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "            for filename in csv_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = 'multi' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_character_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Character errors: {error_stats['character_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "                        if len(df) > 0:\n",
    "                            print(\"Example of the first row:\")\n",
    "                            print(df.iloc[0])\n",
    "            \n",
    "            # JSONL file\n",
    "            jsonl_files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl') and 'trainer_log' not in f]\n",
    "            for filename in jsonl_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_character_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Character errors: {error_stats['character_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "                        if len(df) > 0:\n",
    "                            print(\"Example of the first row:\")\n",
    "                            print(df.iloc[0])\n",
    "    \n",
    "    return results\n",
    "\n",
    "folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/challange/auto/GPT\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\nProcessing fileå¤¹: {folder}\")\n",
    "    results = analyze_files(folder, icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'character_errors_{os.path.basename(folder)}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(\"\\n=== Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d93c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def check_counts(path):\n",
    "    \"\"\"[Translated]ICD[Translated]\"\"\"\n",
    "    for folder_name in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith('.csv'):\n",
    "                    try:\n",
    "                        df = pd.read_csv(os.path.join(folder_path, file))\n",
    "                        total_rows = len(df)\n",
    "                        wrong_count = 0\n",
    "                        \n",
    "                        is_multi = 'multi' in folder_name.lower()\n",
    "                        \n",
    "                        for idx, row in df.iterrows():\n",
    "                            true_codes = convert_to_array(row['label' if 'label' in df.columns else 'ground_truth'])\n",
    "                            true_count = len(true_codes)\n",
    "                            \n",
    "                            pred_codes = extract_icd_codes(row['predict' if 'predict' in df.columns else 'generated_result'])\n",
    "                            pred_count = len(pred_codes)\n",
    "                            \n",
    "                            if (is_multi and pred_count != true_count) or (not is_multi and pred_count != 1):\n",
    "                                wrong_count += 1\n",
    "                        \n",
    "                        error_rate = wrong_count / total_rows if total_rows > 0 else 0\n",
    "                        print(f\"\\nProcessing file: {folder_name}/{file}\")\n",
    "                        print(f\"Total rows: {total_rows}\")\n",
    "                        print(f\"Rows with quantity error: {wrong_count}\")\n",
    "                        print(f\"Error rate: {error_rate:.4f}\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"\\nProcessing fileerror {folder_name}/{file}: {str(e)}\")\n",
    "                        if 'df' in locals():\n",
    "                            print(f\"File column names: {df.columns.tolist()}\")\n",
    "                            if len(df) > 0:\n",
    "                                print(\"Example of the first row:\")\n",
    "                                print(df.iloc[0])\n",
    "\n",
    "path = \"/Users/houzhen/research/LLMCoder/code/challange/auto/GPT\"\n",
    "check_counts(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0fc3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df4fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fbedbb7",
   "metadata": {},
   "source": [
    "# fine tune GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa068056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_icd_codes(code_list):\n",
    "    \"\"\"[Translated]ICD[Translated]\"\"\"\n",
    "    return set(code_list)\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def calculate_existence_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    \n",
    "    predict_col = 'generated_result'  # CSV file\n",
    "    if 'predict' in df.columns:       # JSONL file\n",
    "        predict_col = 'predict'\n",
    "        \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            predicted_codes = convert_to_array(row[predict_col])\n",
    "            if any(code not in icd_codes for code in predicted_codes):\n",
    "                error_rows += 1\n",
    "    else:\n",
    "        predictions = df[predict_col].apply(convert_to_array)\n",
    "        for pred_list in predictions:\n",
    "            if any(code not in icd_codes for code in pred_list):\n",
    "                error_rows += 1\n",
    "    \n",
    "    error_rate = error_rows / total_rows if total_rows > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': total_rows,\n",
    "        'error_samples': error_rows,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder, icd_codes):\n",
    "    \"\"\"Analyze all files in the folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # CSV file\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "            for filename in csv_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = 'multi' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_existence_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Invalid predictions: {error_stats['invalid_predictions']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "            \n",
    "            # JSONL file\n",
    "            jsonl_files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl') and 'trainer_log' not in f]\n",
    "            for filename in jsonl_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_existence_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Invalid predictions: {error_stats['invalid_predictions']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/challange/auto/pure_auto\",\n",
    "\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\nProcessing fileå¤¹: {folder}\")\n",
    "    results = analyze_files(folder, icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'existence_errors_{os.path.basename(folder)}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(\"\\n=== Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66914f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def calculate_level_errors(df, is_multi=False):\n",
    "    \"\"\"Calculate hierarchical errors\"\"\"\n",
    "    total_predictions = 0\n",
    "    level_errors = 0\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row['label' if 'label' in df.columns else 'ground_truth']))\n",
    "            pred_codes = set(convert_to_array(row['predict' if 'predict' in df.columns else 'generated_result']))\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                total_predictions += 1\n",
    "                if any(is_level_error(true_code, pred_code) for true_code in true_codes):\n",
    "                    level_errors += 1\n",
    "    else:\n",
    "        true_col = 'label' if 'label' in df.columns else 'ground_truth'\n",
    "        pred_col = 'predict' if 'predict' in df.columns else 'generated_result'\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row[true_col])\n",
    "            pred_codes = convert_to_array(row[pred_col])\n",
    "            \n",
    "                true_code = true_codes[0]\n",
    "                pred_code = pred_codes[0]\n",
    "                \n",
    "                total_predictions += 1\n",
    "                if is_level_error(true_code, pred_code):\n",
    "                    level_errors += 1\n",
    "    \n",
    "    error_rate = level_errors / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_predictions': total_predictions,\n",
    "        'level_errors': level_errors,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder):\n",
    "    \"\"\"Analyze all files in the folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # CSV file\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "            for filename in csv_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = 'multi' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_level_errors(df, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Hierarchical errors: {error_stats['level_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "            \n",
    "            # JSONL file\n",
    "            jsonl_files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl') and 'trainer_log' not in f]\n",
    "            for filename in jsonl_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_level_errors(df, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Hierarchical errors: {error_stats['level_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/challange/auto/pure_auto\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\nProcessing fileå¤¹: {folder}\")\n",
    "    results = analyze_files(folder)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'level_errors_{os.path.basename(folder)}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(\"\\n=== Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97ab0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def is_character_error(true_code, pred_code, icd_codes):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    # ICD code\n",
    "    if pred_code not in icd_codes:\n",
    "        return False\n",
    "        \n",
    "    if is_level_error(true_code, pred_code):\n",
    "        return False\n",
    "    \n",
    "    true_match = re.match(r'([A-Z])(\\d+.*)', true_code)\n",
    "    pred_match = re.match(r'([A-Z])(\\d+.*)', pred_code)\n",
    "    \n",
    "    if true_match and pred_match:\n",
    "        true_letter, true_nums = true_match.groups()\n",
    "        pred_letter, pred_nums = pred_match.groups()\n",
    "        \n",
    "        if true_letter == pred_letter and true_code != pred_code:\n",
    "            if len(true_code) == len(pred_code):\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def calculate_character_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    total_predictions = 0\n",
    "    char_errors = 0\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row['label' if 'label' in df.columns else 'ground_truth']))\n",
    "            pred_codes = set(convert_to_array(row['predict' if 'predict' in df.columns else 'generated_result']))\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                    total_predictions += 1\n",
    "                    if any(true_code and is_character_error(true_code, pred_code, icd_codes) \n",
    "                          for true_code in true_codes):\n",
    "                        char_errors += 1\n",
    "    else:\n",
    "        true_col = 'label' if 'label' in df.columns else 'ground_truth'\n",
    "        pred_col = 'predict' if 'predict' in df.columns else 'generated_result'\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row[true_col])\n",
    "            pred_codes = convert_to_array(row[pred_col])\n",
    "            \n",
    "                true_code = true_codes[0]\n",
    "                pred_code = pred_codes[0]\n",
    "                \n",
    "                    total_predictions += 1\n",
    "                    if is_character_error(true_code, pred_code, icd_codes):\n",
    "                        char_errors += 1\n",
    "    \n",
    "    error_rate = char_errors / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_predictions': total_predictions,\n",
    "        'character_errors': char_errors,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder, icd_codes):\n",
    "    \"\"\"Analyze all files in the folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # CSV file\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "            for filename in csv_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = 'multi' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_character_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Character errors: {error_stats['character_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "            \n",
    "            # JSONL file\n",
    "            jsonl_files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl') and 'trainer_log' not in f]\n",
    "            for filename in jsonl_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_character_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Character errors: {error_stats['character_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/challange/auto/pure_auto\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\nProcessing fileå¤¹: {folder}\")\n",
    "    results = analyze_files(folder, icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'character_errors_{os.path.basename(folder)}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(\"\\n=== Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc88e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def check_counts(path):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    for folder_name in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith('.csv'):\n",
    "                    df = pd.read_csv(os.path.join(folder_path, file))\n",
    "                    total = len(df)\n",
    "                    if 'multi' in file.lower():\n",
    "                        wrong_count = sum(df['ground_truth'].str.count(',') != df['generated_result'].str.count(','))\n",
    "                    else:\n",
    "                        wrong_count = sum((df['generated_result'].str.count(',') > 0) | df['generated_result'].isna())\n",
    "                    \n",
    "                    print(f\"{folder_name}/{file}: {wrong_count}/{total} = {wrong_count/total:.4f}\")\n",
    "\n",
    "path = \"/Users/houzhen/research/LLMCoder/code/challange/auto/pure_auto\"\n",
    "check_counts(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cc920",
   "metadata": {},
   "source": [
    "# enhance GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73672bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_icd_codes(code_list):\n",
    "    \"\"\"[Translated]ICD[Translated]\"\"\"\n",
    "    return set(code_list)\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def calculate_existence_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    \n",
    "    predict_col = 'generated_result'  # CSV file\n",
    "    if 'predict' in df.columns:       # JSONL file\n",
    "        predict_col = 'predict'\n",
    "        \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            predicted_codes = convert_to_array(row[predict_col])\n",
    "            if any(code not in icd_codes for code in predicted_codes):\n",
    "                error_rows += 1\n",
    "    else:\n",
    "        predictions = df[predict_col].apply(convert_to_array)\n",
    "        for pred_list in predictions:\n",
    "            if any(code not in icd_codes for code in pred_list):\n",
    "                error_rows += 1\n",
    "    \n",
    "    error_rate = error_rows / total_rows if total_rows > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': total_rows,\n",
    "        'error_samples': error_rows,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder, icd_codes):\n",
    "    \"\"\"Analyze all files in the folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # CSV file\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "            for filename in csv_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = 'multi' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_existence_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Invalid predictions: {error_stats['invalid_predictions']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "            \n",
    "            # JSONL file\n",
    "            jsonl_files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl') and 'trainer_log' not in f]\n",
    "            for filename in jsonl_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_existence_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Invalid predictions: {error_stats['invalid_predictions']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/challange/auto/pure_auto_enhance_only_you\",\n",
    "\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\nProcessing fileå¤¹: {folder}\")\n",
    "    results = analyze_files(folder, icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'existence_errors_{os.path.basename(folder)}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(\"\\n=== Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f1b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def calculate_level_errors(df, is_multi=False):\n",
    "    \"\"\"Calculate hierarchical errors\"\"\"\n",
    "    total_predictions = 0\n",
    "    level_errors = 0\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row['label' if 'label' in df.columns else 'ground_truth']))\n",
    "            pred_codes = set(convert_to_array(row['predict' if 'predict' in df.columns else 'generated_result']))\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                total_predictions += 1\n",
    "                if any(is_level_error(true_code, pred_code) for true_code in true_codes):\n",
    "                    level_errors += 1\n",
    "    else:\n",
    "        true_col = 'label' if 'label' in df.columns else 'ground_truth'\n",
    "        pred_col = 'predict' if 'predict' in df.columns else 'generated_result'\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row[true_col])\n",
    "            pred_codes = convert_to_array(row[pred_col])\n",
    "            \n",
    "                true_code = true_codes[0]\n",
    "                pred_code = pred_codes[0]\n",
    "                \n",
    "                total_predictions += 1\n",
    "                if is_level_error(true_code, pred_code):\n",
    "                    level_errors += 1\n",
    "    \n",
    "    error_rate = level_errors / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_predictions': total_predictions,\n",
    "        'level_errors': level_errors,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder):\n",
    "    \"\"\"Analyze all files in the folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # CSV file\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "            for filename in csv_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = 'multi' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_level_errors(df, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Hierarchical errors: {error_stats['level_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "            \n",
    "            # JSONL file\n",
    "            jsonl_files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl') and 'trainer_log' not in f]\n",
    "            for filename in jsonl_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_level_errors(df, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Hierarchical errors: {error_stats['level_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/challange/auto/pure_auto_enhance_only_you\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\nProcessing fileå¤¹: {folder}\")\n",
    "    results = analyze_files(folder)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'level_errors_{os.path.basename(folder)}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(\"\\n=== Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4239d25f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('[') and text.endswith(']'):\n",
    "            try:\n",
    "                return json.loads(text)\n",
    "            except json.JSONDecodeError:\n",
    "                text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "                return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    elif isinstance(text, list):\n",
    "        return text\n",
    "    return []\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def is_character_error(true_code, pred_code, icd_codes):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        \n",
    "    # ICD code\n",
    "    if pred_code not in icd_codes:\n",
    "        return False\n",
    "        \n",
    "    if is_level_error(true_code, pred_code):\n",
    "        return False\n",
    "    \n",
    "    true_match = re.match(r'([A-Z])(\\d+.*)', str(true_code))\n",
    "    pred_match = re.match(r'([A-Z])(\\d+.*)', str(pred_code))\n",
    "    \n",
    "    if true_match and pred_match:\n",
    "        true_letter, true_nums = true_match.groups()\n",
    "        pred_letter, pred_nums = pred_match.groups()\n",
    "        \n",
    "        if true_letter == pred_letter and true_code != pred_code:\n",
    "            if len(true_code) == len(pred_code):\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def calculate_character_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    total_predictions = 0\n",
    "    char_errors = 0\n",
    "    \n",
    "    true_col = 'label' if 'label' in df.columns else 'ground_truth'\n",
    "    pred_col = 'predict' if 'predict' in df.columns else 'generated_result'\n",
    "    \n",
    "    if true_col not in df.columns or pred_col not in df.columns:\n",
    "        print(f\"Warning: Required columns not found. Available columns: {df.columns.tolist()}\")\n",
    "        return {'total_predictions': 0, 'character_errors': 0, 'error_rate': 0}\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row[true_col]))\n",
    "            pred_codes = set(convert_to_array(row[pred_col]))\n",
    "            \n",
    "            if not true_codes or not pred_codes:\n",
    "                continue\n",
    "                \n",
    "            total_predictions += len(pred_codes)\n",
    "            \n",
    "            matched_codes = true_codes.intersection(pred_codes)\n",
    "            \n",
    "            remaining_true = true_codes - matched_codes\n",
    "            remaining_pred = pred_codes - matched_codes\n",
    "            \n",
    "            if remaining_pred:\n",
    "                \n",
    "                for pred_code in remaining_pred.copy():\n",
    "                    for true_code in remaining_true.copy():\n",
    "                        if is_level_error(true_code, pred_code):\n",
    "                            matched_pairs.add((true_code, pred_code))\n",
    "                            remaining_true.discard(true_code)\n",
    "                            remaining_pred.discard(pred_code)\n",
    "                \n",
    "                for pred_code in remaining_pred:\n",
    "                    for true_code in remaining_true:\n",
    "                        if is_character_error(true_code, pred_code, icd_codes):\n",
    "                            char_errors += 1\n",
    "                \n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row[true_col])\n",
    "            pred_codes = convert_to_array(row[pred_col])\n",
    "            \n",
    "                true_code = true_codes[0]\n",
    "                pred_code = pred_codes[0]\n",
    "                \n",
    "                    total_predictions += 1\n",
    "                    if is_character_error(true_code, pred_code, icd_codes):\n",
    "                        char_errors += 1\n",
    "    \n",
    "    error_rate = char_errors / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_predictions': total_predictions,\n",
    "        'character_errors': char_errors,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder, icd_codes):\n",
    "    \"\"\"Analyze all files in the folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # CSV file\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "            for filename in csv_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = 'multi' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_character_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Character errors: {error_stats['character_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    import traceback\n",
    "            \n",
    "            # JSONL file\n",
    "            jsonl_files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl') and 'trainer_log' not in f]\n",
    "            for filename in jsonl_files:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                file_key = f\"{folder_name}/{filename}\"\n",
    "                print(f\"\\nProcessing file: {file_key}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(file_path)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_character_errors(df, icd_codes, is_multi)\n",
    "                    results[file_key] = error_stats\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Character errors: {error_stats['character_errors']}\")\n",
    "                    print(f\"Error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    import traceback\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/challange/auto/pure_auto_enhance_only_you\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    print(f\"\\nProcessing fileå¤¹: {folder}\")\n",
    "    results = analyze_files(folder, icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'character_errors_{os.path.basename(folder)}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(\"\\n=== Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def check_counts(path):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    for folder_name in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith('.csv'):\n",
    "                    df = pd.read_csv(os.path.join(folder_path, file))\n",
    "                    total = len(df)\n",
    "                    if 'multi' in file.lower():\n",
    "                        wrong_count = sum(df['ground_truth'].str.count(',') != df['generated_result'].str.count(','))\n",
    "                    else:\n",
    "                        wrong_count = sum((df['generated_result'].str.count(',') > 0) | df['generated_result'].isna())\n",
    "                    \n",
    "                    print(f\"{folder_name}/{file}: {wrong_count}/{total} = {wrong_count/total:.4f}\")\n",
    "\n",
    "path = \"/Users/houzhen/research/LLMCoder/code/challange/auto/pure_auto_enhance_only_you\"\n",
    "check_counts(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f636f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943669b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53eb3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9f998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17235415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2949dfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d8f6657",
   "metadata": {},
   "source": [
    "# LLAMA 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a52ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def calculate_existence_errors(df, icd_codes, is_multi=False, is_mimic=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    total_predictions = 0\n",
    "    invalid_predictions = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    if is_multi or is_mimic:\n",
    "        for _, row in df.iterrows():\n",
    "            ground_truth = set(convert_to_array(row['label']))\n",
    "            \n",
    "            predicted_codes = set(extract_icd_codes(row['predict']))\n",
    "            \n",
    "            if ground_truth == predicted_codes:\n",
    "                exact_matches += 1\n",
    "            \n",
    "            total_predictions += len(predicted_codes)\n",
    "            invalid_predictions += sum(1 for code in predicted_codes if code not in icd_codes)\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            \n",
    "            if not predicted_codes:\n",
    "                continue\n",
    "                \n",
    "            ground_truth_first = ground_truth[0] if ground_truth else None\n",
    "            predicted_first = predicted_codes[0]\n",
    "            \n",
    "            if ground_truth_first == predicted_first:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "                \n",
    "            if predicted_first not in icd_codes:\n",
    "                invalid_predictions += 1\n",
    "    \n",
    "    error_rate = invalid_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'exact_matches': exact_matches,\n",
    "        'exact_match_rate': exact_matches / len(df),\n",
    "        'remaining_predictions': total_predictions,\n",
    "        'invalid_predictions': invalid_predictions,\n",
    "        'error_rate_on_non_exact': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder, icd_codes):\n",
    "    \"\"\"[Translated]trained[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if not os.path.exists(prediction_file):\n",
    "                prediction_file = os.path.join(folder_path, \"predict.jsonl\")\n",
    "            \n",
    "            if os.path.exists(prediction_file):\n",
    "                print(f\"\\nProcessing file: {prediction_file}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mlti'])\n",
    "                    is_mimic = 'mimic' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_existence_errors(df, icd_codes, is_multi, is_mimic)\n",
    "                    results[folder_name] = error_stats\n",
    "                    \n",
    "                    print(f\"Total samples: {error_stats['total_samples']}\")\n",
    "                    print(f\"Exact matches: {error_stats['exact_matches']}\")\n",
    "                    print(f\"Exact match rate: {error_stats['exact_match_rate']:.4f}\")\n",
    "                    print(f\"Remaining predictions: {error_stats['remaining_predictions']}\")\n",
    "                    print(f\"Invalid predictions: {error_stats['invalid_predictions']}\")\n",
    "                    print(f\"Error rate on non-exact matches: {error_stats['error_rate_on_non_exact']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/1b/notrain\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/3b/notrain\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/8b/notrain\"\n",
    "]\n",
    "\n",
    "for folder in llama_folders:\n",
    "    print(f\"\\nProcessing Llama {model_size} trainedmodel\")\n",
    "    results = analyze_files(folder, icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'existence_errors_llama_{model_size}_trained.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} trained ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def calculate_level_errors(df, is_multi=False, is_mimic=False):\n",
    "    \"\"\"Calculate hierarchical errors\"\"\"\n",
    "    total_predictions = 0\n",
    "    level_errors = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    if is_multi or is_mimic:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row['label']))\n",
    "            pred_codes = set(extract_icd_codes(row['predict']))\n",
    "            \n",
    "            if true_codes == pred_codes:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                total_predictions += 1\n",
    "                if any(is_level_error(true_code, pred_code) for true_code in true_codes):\n",
    "                    level_errors += 1\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row['label'])\n",
    "            pred_codes = extract_icd_codes(row['predict'])\n",
    "            \n",
    "            if true_codes and pred_codes:\n",
    "                if true_codes[0] == pred_codes[0]:\n",
    "                    exact_matches += 1\n",
    "                    continue\n",
    "                    \n",
    "                total_predictions += 1\n",
    "                if is_level_error(true_codes[0], pred_codes[0]):\n",
    "                    level_errors += 1\n",
    "    \n",
    "    error_rate = level_errors / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'exact_matches': exact_matches,\n",
    "        'exact_match_rate': exact_matches / len(df) if len(df) > 0 else 0,\n",
    "        'total_predictions': total_predictions,\n",
    "        'level_errors': level_errors,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_llama_folder(root_folder):\n",
    "    \"\"\"[Translated]LLAMA[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if os.path.exists(prediction_file):\n",
    "                print(f\"\\nProcessing file: {prediction_file}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mlti'])\n",
    "                    is_mimic = 'mimic' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_level_errors(df, is_multi, is_mimic)\n",
    "                    results[folder_name] = error_stats\n",
    "                    \n",
    "                    print(f\"Total samples: {error_stats['total_samples']}\")\n",
    "                    print(f\"Exact matches: {error_stats['exact_matches']}\")\n",
    "                    print(f\"Exact match rate: {error_stats['exact_match_rate']:.4f}\")\n",
    "                    print(f\"Predictions for hierarchical error evaluation: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Hierarchical errors: {error_stats['level_errors']}\")\n",
    "                    print(f\"Hierarchical error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/1b/notrain\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/3b/notrain\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/8b/notrain\"\n",
    "]\n",
    "\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\nProcessing Llama {model_size} model\")\n",
    "    results = analyze_llama_folder(folder)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'level_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75187d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_character_error(true_code, pred_code, icd_codes):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    if pred_code not in icd_codes:\n",
    "        return True\n",
    "    \n",
    "    if true_code == pred_code:\n",
    "        return False\n",
    "    \n",
    "    true_base = re.match(r'([A-Z]\\d+)', true_code)\n",
    "    pred_base = re.match(r'([A-Z]\\d+)', pred_code)\n",
    "    \n",
    "    if not true_base or not pred_base:\n",
    "        return True\n",
    "    \n",
    "    true_chars = list(true_code)\n",
    "    pred_chars = list(pred_code)\n",
    "    \n",
    "    if len(true_chars) != len(pred_chars):\n",
    "        return True\n",
    "    \n",
    "    for t_char, p_char in zip(true_chars, pred_chars):\n",
    "        if t_char != p_char:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def calculate_character_errors(df, icd_codes, is_multi=False, is_mimic=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    total_predictions = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    if is_multi or is_mimic:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row['label']))\n",
    "            pred_codes = set(extract_icd_codes(row['predict']))\n",
    "            \n",
    "            if true_codes == pred_codes:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                    continue\n",
    "                    \n",
    "                total_predictions += 1\n",
    "                \n",
    "                if pred_code not in icd_codes:\n",
    "                    invalid_codes += 1\n",
    "                    continue\n",
    "                \n",
    "                if any(is_level_error(true_code, pred_code) for true_code in true_codes):\n",
    "                    level_errors += 1\n",
    "                elif pred_code not in true_codes:\n",
    "                    other_char_errors += 1\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row['label'])\n",
    "            pred_codes = extract_icd_codes(row['predict'])\n",
    "            \n",
    "            if not true_codes or not pred_codes:\n",
    "                continue\n",
    "                \n",
    "            true_code = true_codes[0]\n",
    "            pred_code = pred_codes[0]\n",
    "            \n",
    "            if true_code == pred_code:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "                \n",
    "            total_predictions += 1\n",
    "            \n",
    "            if pred_code not in icd_codes:\n",
    "                invalid_codes += 1\n",
    "            elif is_level_error(true_code, pred_code):\n",
    "                level_errors += 1\n",
    "            else:\n",
    "                other_char_errors += 1\n",
    "    \n",
    "    total_errors = level_errors + invalid_codes + other_char_errors\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'exact_matches': exact_matches,\n",
    "        'exact_match_rate': exact_matches / len(df) if len(df) > 0 else 0,\n",
    "        'total_predictions': total_predictions,\n",
    "        'level_errors': level_errors,\n",
    "        'level_error_rate': level_errors / total_predictions if total_predictions > 0 else 0,\n",
    "        'invalid_codes': invalid_codes,\n",
    "        'invalid_code_rate': invalid_codes / total_predictions if total_predictions > 0 else 0,\n",
    "        'other_char_errors': other_char_errors,\n",
    "        'other_error_rate': other_char_errors / total_predictions if total_predictions > 0 else 0,\n",
    "        'total_error_rate': total_errors / total_predictions if total_predictions > 0 else 0\n",
    "    }\n",
    "\n",
    "def analyze_llama_folder(root_folder, icd_codes):\n",
    "    \"\"\"[Translated]LLAMA[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if os.path.exists(prediction_file):\n",
    "                print(f\"\\nProcessing file: {prediction_file}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mlti'])\n",
    "                    is_mimic = 'mimic' in folder_name.lower()\n",
    "                    \n",
    "                    error_stats = calculate_character_errors(df, icd_codes, is_multi, is_mimic)\n",
    "                    \n",
    "                    results[folder_name] = {\n",
    "                        'total_predictions': error_stats['total_predictions'],\n",
    "                        'other_char_errors': error_stats['other_char_errors'],\n",
    "                        'char_error_rate': error_stats['other_error_rate']\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Character errors: {error_stats['other_char_errors']}\")\n",
    "                    print(f\"Character error rate: {error_stats['other_error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def collect_valid_codes(folders):\n",
    "    \"\"\"[Translated]label[Translated]ICD[Translated]\"\"\"\n",
    "    valid_codes = set()\n",
    "    for folder in folders:\n",
    "        for folder_name in os.listdir(folder):\n",
    "            folder_path = os.path.join(folder, folder_name)\n",
    "            \n",
    "            if os.path.isdir(folder_path):\n",
    "                prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "                if os.path.exists(prediction_file):\n",
    "                    try:\n",
    "                        df = load_jsonl(prediction_file)\n",
    "                        for _, row in df.iterrows():\n",
    "                            codes = convert_to_array(row['label'])\n",
    "                            valid_codes.update(codes)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Processing fileerror: {str(e)}\")\n",
    "    return valid_codes\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/1b/notrain\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/3b/notrain\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/8b/notrain\"\n",
    "]\n",
    "\n",
    "# ICD code\n",
    "print(\"Collecting valid ICD codes...\")\n",
    "valid_icd_codes = collect_valid_codes(llama_folders)\n",
    "print(f\"Collected {len(valid_icd_codes)} valid ICD codes\")\n",
    "\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\nProcessing Llama {model_size} model\")\n",
    "    results = analyze_llama_folder(folder, valid_icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'character_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} å­ç¬¦éè¯¯ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d89438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc93d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a5946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf659307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"[Translated]JSONL[Translated]\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"[Translated]ICD[Translated]\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*[A-Z]?', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def check_counts_llama(path):\n",
    "    \"\"\"[Translated]LLAMA[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if os.path.exists(prediction_file):\n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    total = len(df)\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mlti'])\n",
    "                    is_mimic = 'mimic' in folder_name.lower()\n",
    "                    \n",
    "                    wrong_count = 0\n",
    "                    for idx, row in df.iterrows():\n",
    "                        true_codes = convert_to_array(row['label'])\n",
    "                        true_count = len(true_codes)\n",
    "                        \n",
    "                        pred_codes = extract_icd_codes(row['predict'])\n",
    "                        \n",
    "                        if is_multi or is_mimic:\n",
    "                            if len(pred_codes) != true_count:\n",
    "                                wrong_count += 1\n",
    "                                    print(f\"\\nExample - {folder_name}:\")\n",
    "                                    print(f\"Label ({true_count}): {row['label']}\")\n",
    "                                    print(f\"Predict ({len(pred_codes)}): {row['predict']}\")\n",
    "                                    print(f\"Extracted codes: {pred_codes}\")\n",
    "                        else:\n",
    "                            if len(pred_codes) != 1:\n",
    "                                wrong_count += 1\n",
    "                                    print(f\"\\nExample - {folder_name}:\")\n",
    "                                    print(f\"Label ({true_count}): {row['label']}\")\n",
    "                                    print(f\"Predict ({len(pred_codes)}): {row['predict']}\")\n",
    "                                    print(f\"Extracted codes: {pred_codes}\")\n",
    "                    \n",
    "                    error_rate = wrong_count/total if total > 0 else 0\n",
    "                    print(f\"{folder_name}: {wrong_count}/{total} = {error_rate:.4f}\")\n",
    "                    \n",
    "                    results[folder_name] = {\n",
    "                        'total_samples': total,\n",
    "                        'wrong_count': wrong_count,\n",
    "                        'error_rate': error_rate\n",
    "                    }\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/1b/notrain\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/3b/notrain\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/8b/notrain\"\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\n=== Llama {model_size} model ===\")\n",
    "    results = check_counts_llama(folder)\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    \n",
    "    output_file = f'count_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())\n",
    "    \n",
    "    all_results[model_size] = results\n",
    "\n",
    "all_results_df = pd.concat([pd.DataFrame.from_dict(res, orient='index').assign(model=size) \n",
    "                          for size, res in all_results.items()])\n",
    "all_results_df.to_csv('count_errors_llama_all.csv')\n",
    "\n",
    "print(\"\\n=== ææmodelæ±æ» ===\")\n",
    "for size, res in all_results.items():\n",
    "    print(f\"\\n{size} modelå¹³åError rate: {pd.DataFrame(res).loc['error_rate'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c9394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003e26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff61c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfdcdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864d619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d85602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57acd7df",
   "metadata": {},
   "source": [
    "# fine tuned LLAma 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80496e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def calculate_existence_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    total_predictions = 0\n",
    "    invalid_predictions = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            ground_truth = set(convert_to_array(row['label']))\n",
    "            \n",
    "            if 'mimic' in str(row.get('dataset', '')).lower():\n",
    "                predicted_codes = set(extract_icd_codes(row['predict']))\n",
    "            else:\n",
    "                predicted_codes = set(convert_to_array(row['predict']))\n",
    "            \n",
    "            if ground_truth == predicted_codes:\n",
    "                exact_matches += 1\n",
    "            \n",
    "            total_predictions += len(predicted_codes)\n",
    "            invalid_predictions += sum(1 for code in predicted_codes if code not in icd_codes)\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            pred_codes = set(convert_to_array(row['predict']))\n",
    "            \n",
    "            if ground_truth == pred_codes:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "                \n",
    "            total_predictions += len(pred_codes)\n",
    "            invalid_predictions += sum(1 for code in pred_codes if code not in icd_codes)\n",
    "    \n",
    "    error_rate = invalid_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'exact_matches': exact_matches,\n",
    "        'exact_match_rate': exact_matches / len(df),\n",
    "        'remaining_predictions': total_predictions,\n",
    "        'invalid_predictions': invalid_predictions,\n",
    "        'error_rate_on_non_exact': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder, icd_codes):\n",
    "    \"\"\"[Translated]trained[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if not os.path.exists(prediction_file):\n",
    "                prediction_file = os.path.join(folder_path, \"predict.jsonl\")\n",
    "            \n",
    "            if os.path.exists(prediction_file):\n",
    "                print(f\"\\nProcessing file: {prediction_file}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_existence_errors(df, icd_codes, is_multi)\n",
    "                    results[folder_name] = error_stats\n",
    "                    \n",
    "                    print(f\"Total samples: {error_stats['total_samples']}\")\n",
    "                    print(f\"Exact matches: {error_stats['exact_matches']}\")\n",
    "                    print(f\"Exact match rate: {error_stats['exact_match_rate']:.4f}\")\n",
    "                    print(f\"Remaining predictions: {error_stats['remaining_predictions']}\")\n",
    "                    print(f\"Invalid predictions: {error_stats['invalid_predictions']}\")\n",
    "                    print(f\"Error rate on non-exact matches: {error_stats['error_rate_on_non_exact']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ICD code\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/1b/train\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/3b/train\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/8b/train\"\n",
    "]\n",
    "\n",
    "for folder in llama_folders:\n",
    "    print(f\"\\nProcessing Llama {model_size} trainedmodel\")\n",
    "    results = analyze_files(folder, icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'existence_errors_llama_{model_size}_trained.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} trained ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c4aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def calculate_level_errors(df, is_multi=False, is_mimic=False):\n",
    "    \"\"\"Calculate hierarchical errors\"\"\"\n",
    "    total_predictions = 0\n",
    "    level_errors = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row['label']))\n",
    "            \n",
    "            if is_mimic:\n",
    "                pred_codes = set(extract_icd_codes(row['predict']))\n",
    "            else:\n",
    "                pred_codes = set(convert_to_array(row['predict']))\n",
    "            \n",
    "            if true_codes == pred_codes:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                total_predictions += 1\n",
    "                if any(is_level_error(true_code, pred_code) for true_code in true_codes):\n",
    "                    level_errors += 1\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row['label'])\n",
    "            pred_codes = convert_to_array(row['predict'])\n",
    "            \n",
    "            if set(true_codes) == set(pred_codes):\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "                \n",
    "            if true_codes and pred_codes:\n",
    "                true_code = true_codes[0]\n",
    "                pred_code = pred_codes[0]\n",
    "                \n",
    "                total_predictions += 1\n",
    "                if is_level_error(true_code, pred_code):\n",
    "                    level_errors += 1\n",
    "    \n",
    "    error_rate = level_errors / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'exact_matches': exact_matches,\n",
    "        'exact_match_rate': exact_matches / len(df) if len(df) > 0 else 0,\n",
    "        'total_predictions': total_predictions,\n",
    "        'level_errors': level_errors,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_llama_folder(root_folder):\n",
    "    \"\"\"[Translated]LLAMA[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if os.path.exists(prediction_file):\n",
    "                print(f\"\\nProcessing file: {prediction_file}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    is_mimic = any(x in folder_name.lower() for x in ['mimic'])\n",
    "                    \n",
    "                    error_stats = calculate_level_errors(df, is_multi, is_mimic)\n",
    "                    results[folder_name] = error_stats\n",
    "                    \n",
    "                    print(f\"Total samples: {error_stats['total_samples']}\")\n",
    "                    print(f\"Exact matches: {error_stats['exact_matches']}\")\n",
    "                    print(f\"Exact match rate: {error_stats['exact_match_rate']:.4f}\")\n",
    "                    print(f\"Predictions for hierarchical error evaluation: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Hierarchical errors: {error_stats['level_errors']}\")\n",
    "                    print(f\"Hierarchical error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/1b/train\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/3b/train\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/8b/train\"\n",
    "]\n",
    "\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\nProcessing Llama {model_size} model\")\n",
    "    results = analyze_llama_folder(folder)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'level_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fee3a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_character_error(true_code, pred_code, icd_codes):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    if pred_code not in icd_codes:\n",
    "        return True\n",
    "    \n",
    "    if true_code == pred_code:\n",
    "        return False\n",
    "    \n",
    "    true_base = re.match(r'([A-Z]\\d+)', true_code)\n",
    "    pred_base = re.match(r'([A-Z]\\d+)', pred_code)\n",
    "    \n",
    "    if not true_base or not pred_base:\n",
    "        return True\n",
    "    \n",
    "    true_chars = list(true_code)\n",
    "    pred_chars = list(pred_code)\n",
    "    \n",
    "    if len(true_chars) != len(pred_chars):\n",
    "        return True\n",
    "    \n",
    "    for t_char, p_char in zip(true_chars, pred_chars):\n",
    "        if t_char != p_char:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def calculate_character_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    total_predictions = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row['label']))\n",
    "            \n",
    "            if 'mimic' in str(row.get('dataset', '')).lower() or 'mimic' in os.path.basename(os.getcwd()).lower():\n",
    "                pred_codes = set(extract_icd_codes(row['predict']))\n",
    "            else:\n",
    "                pred_codes = set(convert_to_array(row['predict']))\n",
    "            \n",
    "            if true_codes == pred_codes:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                    continue\n",
    "                    \n",
    "                total_predictions += 1\n",
    "                \n",
    "                if pred_code not in icd_codes:\n",
    "                    invalid_codes += 1\n",
    "                    continue\n",
    "                \n",
    "                if any(is_level_error(true_code, pred_code) for true_code in true_codes):\n",
    "                    level_errors += 1\n",
    "                elif pred_code not in true_codes:\n",
    "                    other_char_errors += 1\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row['label'])\n",
    "            \n",
    "            if 'mimic' in str(row.get('dataset', '')).lower() or 'mimic' in os.path.basename(os.getcwd()).lower():\n",
    "                pred_codes = extract_icd_codes(row['predict'])\n",
    "            else:\n",
    "                pred_codes = convert_to_array(row['predict'])\n",
    "            \n",
    "            if set(true_codes) == set(pred_codes):\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "            \n",
    "            if true_codes and pred_codes:\n",
    "                true_code = true_codes[0]\n",
    "                pred_code = pred_codes[0]\n",
    "                \n",
    "                    continue\n",
    "                    \n",
    "                total_predictions += 1\n",
    "                \n",
    "                if pred_code not in icd_codes:\n",
    "                    invalid_codes += 1\n",
    "                elif is_level_error(true_code, pred_code):\n",
    "                    level_errors += 1\n",
    "                elif pred_code != true_code:\n",
    "                    other_char_errors += 1\n",
    "    \n",
    "    total_errors = level_errors + invalid_codes + other_char_errors\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'exact_matches': exact_matches,\n",
    "        'exact_match_rate': exact_matches / len(df) if len(df) > 0 else 0,\n",
    "        'total_predictions': total_predictions,\n",
    "        'level_errors': level_errors,\n",
    "        'level_error_rate': level_errors / total_predictions if total_predictions > 0 else 0,\n",
    "        'invalid_codes': invalid_codes,\n",
    "        'invalid_code_rate': invalid_codes / total_predictions if total_predictions > 0 else 0,\n",
    "        'other_char_errors': other_char_errors,\n",
    "        'other_error_rate': other_char_errors / total_predictions if total_predictions > 0 else 0,\n",
    "        'total_error_rate': total_errors / total_predictions if total_predictions > 0 else 0\n",
    "    }\n",
    "\n",
    "def analyze_llama_folder(root_folder, icd_codes):\n",
    "    \"\"\"[Translated]LLAMA[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if os.path.exists(prediction_file):\n",
    "                print(f\"\\nProcessing file: {prediction_file}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_character_errors(df, icd_codes, is_multi)\n",
    "                    \n",
    "                    results[folder_name] = {\n",
    "                        'total_predictions': error_stats['total_predictions'],\n",
    "                        'other_char_errors': error_stats['other_char_errors'],\n",
    "                        'char_error_rate': error_stats['other_error_rate']\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Character errors: {error_stats['other_char_errors']}\")\n",
    "                    print(f\"Character error rate: {error_stats['other_error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\nProcessing Llama {model_size} model\")\n",
    "    results = analyze_llama_folder(folder, valid_icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'char_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} å­ç¬¦éè¯¯ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())\n",
    "\n",
    "# ICD code\n",
    "def collect_valid_codes(folders):\n",
    "    valid_codes = set()\n",
    "    for folder in folders:\n",
    "        for folder_name in os.listdir(folder):\n",
    "            folder_path = os.path.join(folder, folder_name)\n",
    "            \n",
    "            if os.path.isdir(folder_path):\n",
    "                prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "                if os.path.exists(prediction_file):\n",
    "                    try:\n",
    "                        df = load_jsonl(prediction_file)\n",
    "                        for _, row in df.iterrows():\n",
    "                            codes = convert_to_array(row['label'])\n",
    "                            valid_codes.update(codes)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Processing fileerror: {str(e)}\")\n",
    "    return valid_codes\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/1b/train\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/3b/train\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/8b/train\"\n",
    "]\n",
    "\n",
    "# ICD code\n",
    "print(\"Collecting valid ICD codes...\")\n",
    "valid_icd_codes = collect_valid_codes(llama_folders)\n",
    "print(f\"Collected {len(valid_icd_codes)} valid ICD codes\")\n",
    "\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\nProcessing Llama {model_size} model\")\n",
    "    results = analyze_llama_folder(folder, valid_icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'char_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} å­ç¬¦éè¯¯ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569a468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"[Translated]JSONL[Translated]\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"[Translated]ICD[Translated]\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*[A-Z]?', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def get_code_count(text):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            cleaned = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return len([x for x in cleaned.split(',') if x.strip()])\n",
    "        elif re.match(r'^[A-Z]\\d{2}\\.?\\d*[A-Z]?$', text.strip()):\n",
    "            return 1\n",
    "        else:\n",
    "            codes = extract_icd_codes(text)\n",
    "            return len(codes)\n",
    "    return 0\n",
    "\n",
    "def check_counts_llama(path):\n",
    "    \"\"\"[Translated]LLAMA[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if os.path.exists(prediction_file):\n",
    "                df = load_jsonl(prediction_file)\n",
    "                total = len(df)\n",
    "                \n",
    "                is_mimic = 'mimic' in folder_name.lower()\n",
    "                \n",
    "                wrong_count = 0\n",
    "                for _, row in df.iterrows():\n",
    "                    label_count = get_code_count(row['label'])\n",
    "                    \n",
    "                    if is_mimic:\n",
    "                        pred_codes = extract_icd_codes(row['predict'])\n",
    "                        pred_count = len(pred_codes)\n",
    "                    else:\n",
    "                        pred_count = get_code_count(row['predict'])\n",
    "                    \n",
    "                    if label_count != pred_count:\n",
    "                        wrong_count += 1\n",
    "                            print(f\"\\nExample - {folder_name}:\")\n",
    "                            print(f\"Label ({label_count}): {row['label']}\")\n",
    "                            print(f\"Predict ({pred_count}): {row['predict']}\")\n",
    "                            if is_mimic or not row['predict'].startswith('['):\n",
    "                                extracted_codes = extract_icd_codes(row['predict'])\n",
    "                                print(f\"Extracted codes: {extracted_codes}\")\n",
    "                \n",
    "                error_rate = wrong_count/total if total > 0 else 0\n",
    "                print(f\"{folder_name}: {wrong_count}/{total} = {error_rate:.4f}\")\n",
    "                \n",
    "                results[folder_name] = {\n",
    "                    'total_samples': total,\n",
    "                    'wrong_count': wrong_count,\n",
    "                    'error_rate': error_rate\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/1b/train\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/3b/train\",\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/8b/train\"\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\n=== Llama {model_size} model ===\")\n",
    "    results = check_counts_llama(folder)\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    \n",
    "    output_file = f'count_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())\n",
    "    \n",
    "    all_results[model_size] = results\n",
    "\n",
    "all_results_df = pd.concat([pd.DataFrame.from_dict(res, orient='index').assign(model=size) \n",
    "                          for size, res in all_results.items()])\n",
    "all_results_df.to_csv('count_errors_llama_all.csv')\n",
    "\n",
    "print(\"\\n=== ææmodelæ±æ» ===\")\n",
    "for size, res in all_results.items():\n",
    "    print(f\"\\n{size} modelå¹³åError rate: {pd.DataFrame(res).loc['error_rate'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9cd5b",
   "metadata": {},
   "source": [
    "# enhance llama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebac800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = '/Users/houzhen/research/LLMCoder/code/llama_auto/enhance/mimc_test/generated_predictions.jsonl'\n",
    "output_file_path = '/Users/houzhen/research/LLMCoder/code/llama_auto/enhance/mimc_test/modified_predictions.jsonl'\n",
    "\n",
    "modified_data = []\n",
    "\n",
    "with open(input_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        if 'label' in data:\n",
    "            if isinstance(data['label'], str):\n",
    "                labels = data['label'].split(', ')\n",
    "            elif isinstance(data['label'], list):\n",
    "                data['label'] = json.dumps(data['label'])\n",
    "        \n",
    "        if 'predict' in data:\n",
    "            if isinstance(data['predict'], str):\n",
    "                predicts = data['predict'].split(', ')\n",
    "                data['predict'] = json.dumps(predicts)\n",
    "            elif isinstance(data['predict'], list):\n",
    "                data['predict'] = json.dumps(data['predict'])\n",
    "        \n",
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    for item in modified_data:\n",
    "\n",
    "print(\"File successfully saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e4dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def calculate_existence_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    total_predictions = 0\n",
    "    invalid_predictions = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            ground_truth = set(convert_to_array(row['label']))\n",
    "            \n",
    "            if 'mimic' in str(row.get('dataset', '')).lower():\n",
    "                predicted_codes = set(extract_icd_codes(row['predict']))\n",
    "            else:\n",
    "                predicted_codes = set(convert_to_array(row['predict']))\n",
    "            \n",
    "            if ground_truth == predicted_codes:\n",
    "                exact_matches += 1\n",
    "            \n",
    "            total_predictions += len(predicted_codes)\n",
    "            invalid_predictions += sum(1 for code in predicted_codes if code not in icd_codes)\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            pred_codes = set(convert_to_array(row['predict']))\n",
    "            \n",
    "            if ground_truth == pred_codes:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "                \n",
    "            total_predictions += len(pred_codes)\n",
    "            invalid_predictions += sum(1 for code in pred_codes if code not in icd_codes)\n",
    "    \n",
    "    error_rate = invalid_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'exact_matches': exact_matches,\n",
    "        'exact_match_rate': exact_matches / len(df),\n",
    "        'remaining_predictions': total_predictions,\n",
    "        'invalid_predictions': invalid_predictions,\n",
    "        'error_rate_on_non_exact': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_files(root_folder, icd_codes):\n",
    "    \"\"\"[Translated]trained[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if not os.path.exists(prediction_file):\n",
    "                prediction_file = os.path.join(folder_path, \"predict.jsonl\")\n",
    "            \n",
    "            if os.path.exists(prediction_file):\n",
    "                print(f\"\\nProcessing file: {prediction_file}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_existence_errors(df, icd_codes, is_multi)\n",
    "                    results[folder_name] = error_stats\n",
    "                    \n",
    "                    print(f\"Total samples: {error_stats['total_samples']}\")\n",
    "                    print(f\"Exact matches: {error_stats['exact_matches']}\")\n",
    "                    print(f\"Exact match rate: {error_stats['exact_match_rate']:.4f}\")\n",
    "                    print(f\"Remaining predictions: {error_stats['remaining_predictions']}\")\n",
    "                    print(f\"Invalid predictions: {error_stats['invalid_predictions']}\")\n",
    "                    print(f\"Error rate on non-exact matches: {error_stats['error_rate_on_non_exact']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ICD code\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/enhance\",\n",
    "]\n",
    "\n",
    "for folder in llama_folders:\n",
    "    print(f\"\\nProcessing Llama {model_size} trainedmodel\")\n",
    "    results = analyze_files(folder, icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'existence_errors_llama_{model_size}_trained.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} trained ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681272bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def calculate_level_errors(df, is_multi=False, is_mimic=False):\n",
    "    \"\"\"Calculate hierarchical errors\"\"\"\n",
    "    total_predictions = 0\n",
    "    level_errors = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row['label']))\n",
    "            \n",
    "            if is_mimic:\n",
    "                pred_codes = set(extract_icd_codes(row['predict']))\n",
    "            else:\n",
    "                pred_codes = set(convert_to_array(row['predict']))\n",
    "            \n",
    "            if true_codes == pred_codes:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                total_predictions += 1\n",
    "                if any(is_level_error(true_code, pred_code) for true_code in true_codes):\n",
    "                    level_errors += 1\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row['label'])\n",
    "            pred_codes = convert_to_array(row['predict'])\n",
    "            \n",
    "            if set(true_codes) == set(pred_codes):\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "                \n",
    "            if true_codes and pred_codes:\n",
    "                true_code = true_codes[0]\n",
    "                pred_code = pred_codes[0]\n",
    "                \n",
    "                total_predictions += 1\n",
    "                if is_level_error(true_code, pred_code):\n",
    "                    level_errors += 1\n",
    "    \n",
    "    error_rate = level_errors / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'exact_matches': exact_matches,\n",
    "        'exact_match_rate': exact_matches / len(df) if len(df) > 0 else 0,\n",
    "        'total_predictions': total_predictions,\n",
    "        'level_errors': level_errors,\n",
    "        'error_rate': error_rate\n",
    "    }\n",
    "\n",
    "def analyze_llama_folder(root_folder):\n",
    "    \"\"\"[Translated]LLAMA[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if os.path.exists(prediction_file):\n",
    "                print(f\"\\nProcessing file: {prediction_file}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    is_mimic = any(x in folder_name.lower() for x in ['mimic'])\n",
    "                    \n",
    "                    error_stats = calculate_level_errors(df, is_multi, is_mimic)\n",
    "                    results[folder_name] = error_stats\n",
    "                    \n",
    "                    print(f\"Total samples: {error_stats['total_samples']}\")\n",
    "                    print(f\"Exact matches: {error_stats['exact_matches']}\")\n",
    "                    print(f\"Exact match rate: {error_stats['exact_match_rate']:.4f}\")\n",
    "                    print(f\"Predictions for hierarchical error evaluation: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Hierarchical errors: {error_stats['level_errors']}\")\n",
    "                    print(f\"Hierarchical error rate: {error_stats['error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/enhance\",\n",
    "]\n",
    "\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\nProcessing Llama {model_size} model\")\n",
    "    results = analyze_llama_folder(folder)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'level_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46897e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and convert to DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"Extract all ICD codes from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # ICD code\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def convert_to_array(text):\n",
    "    \"\"\"Convert a string-formatted array into an actual array\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            text = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return [item.strip() for item in text.split(',') if item.strip()]\n",
    "        else:\n",
    "            return [text.strip()]\n",
    "    return []\n",
    "\n",
    "def is_character_error(true_code, pred_code, icd_codes):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    if pred_code not in icd_codes:\n",
    "        return True\n",
    "    \n",
    "    if true_code == pred_code:\n",
    "        return False\n",
    "    \n",
    "    true_base = re.match(r'([A-Z]\\d+)', true_code)\n",
    "    pred_base = re.match(r'([A-Z]\\d+)', pred_code)\n",
    "    \n",
    "    if not true_base or not pred_base:\n",
    "        return True\n",
    "    \n",
    "    true_chars = list(true_code)\n",
    "    pred_chars = list(pred_code)\n",
    "    \n",
    "    if len(true_chars) != len(pred_chars):\n",
    "        return True\n",
    "    \n",
    "    for t_char, p_char in zip(true_chars, pred_chars):\n",
    "        if t_char != p_char:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def is_level_error(true_code, pred_code):\n",
    "    if not true_code or not pred_code:\n",
    "        return False\n",
    "        return False\n",
    "    return true_code in pred_code or pred_code in true_code\n",
    "\n",
    "def calculate_character_errors(df, icd_codes, is_multi=False):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    total_predictions = 0\n",
    "    exact_matches = 0\n",
    "    \n",
    "    if is_multi:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = set(convert_to_array(row['label']))\n",
    "            \n",
    "            if 'mimic' in str(row.get('dataset', '')).lower() or 'mimic' in os.path.basename(os.getcwd()).lower():\n",
    "                pred_codes = set(extract_icd_codes(row['predict']))\n",
    "            else:\n",
    "                pred_codes = set(convert_to_array(row['predict']))\n",
    "            \n",
    "            if true_codes == pred_codes:\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "            \n",
    "            for pred_code in pred_codes:\n",
    "                    continue\n",
    "                    \n",
    "                total_predictions += 1\n",
    "                \n",
    "                if pred_code not in icd_codes:\n",
    "                    invalid_codes += 1\n",
    "                    continue\n",
    "                \n",
    "                if any(is_level_error(true_code, pred_code) for true_code in true_codes):\n",
    "                    level_errors += 1\n",
    "                elif pred_code not in true_codes:\n",
    "                    other_char_errors += 1\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            true_codes = convert_to_array(row['label'])\n",
    "            \n",
    "            if 'mimic' in str(row.get('dataset', '')).lower() or 'mimic' in os.path.basename(os.getcwd()).lower():\n",
    "                pred_codes = extract_icd_codes(row['predict'])\n",
    "            else:\n",
    "                pred_codes = convert_to_array(row['predict'])\n",
    "            \n",
    "            if set(true_codes) == set(pred_codes):\n",
    "                exact_matches += 1\n",
    "                continue\n",
    "            \n",
    "            if true_codes and pred_codes:\n",
    "                true_code = true_codes[0]\n",
    "                pred_code = pred_codes[0]\n",
    "                \n",
    "                    continue\n",
    "                    \n",
    "                total_predictions += 1\n",
    "                \n",
    "                if pred_code not in icd_codes:\n",
    "                    invalid_codes += 1\n",
    "                elif is_level_error(true_code, pred_code):\n",
    "                    level_errors += 1\n",
    "                elif pred_code != true_code:\n",
    "                    other_char_errors += 1\n",
    "    \n",
    "    total_errors = level_errors + invalid_codes + other_char_errors\n",
    "    \n",
    "    return {\n",
    "        'total_samples': len(df),\n",
    "        'exact_matches': exact_matches,\n",
    "        'exact_match_rate': exact_matches / len(df) if len(df) > 0 else 0,\n",
    "        'total_predictions': total_predictions,\n",
    "        'level_errors': level_errors,\n",
    "        'level_error_rate': level_errors / total_predictions if total_predictions > 0 else 0,\n",
    "        'invalid_codes': invalid_codes,\n",
    "        'invalid_code_rate': invalid_codes / total_predictions if total_predictions > 0 else 0,\n",
    "        'other_char_errors': other_char_errors,\n",
    "        'other_error_rate': other_char_errors / total_predictions if total_predictions > 0 else 0,\n",
    "        'total_error_rate': total_errors / total_predictions if total_predictions > 0 else 0\n",
    "    }\n",
    "\n",
    "def analyze_llama_folder(root_folder, icd_codes):\n",
    "    \"\"\"[Translated]LLAMA[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Analyzing folder: {folder_name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if os.path.exists(prediction_file):\n",
    "                print(f\"\\nProcessing file: {prediction_file}\")\n",
    "                \n",
    "                try:\n",
    "                    df = load_jsonl(prediction_file)\n",
    "                    print(f\"Number of rows: {len(df)}\")\n",
    "                    \n",
    "                    is_multi = any(x in folder_name.lower() for x in ['multi', 'mimic', 'mlti'])\n",
    "                    \n",
    "                    error_stats = calculate_character_errors(df, icd_codes, is_multi)\n",
    "                    \n",
    "                    results[folder_name] = {\n",
    "                        'total_predictions': error_stats['total_predictions'],\n",
    "                        'other_char_errors': error_stats['other_char_errors'],\n",
    "                        'char_error_rate': error_stats['other_error_rate']\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"Total predictions: {error_stats['total_predictions']}\")\n",
    "                    print(f\"Character errors: {error_stats['other_char_errors']}\")\n",
    "                    print(f\"Character error rate: {error_stats['other_error_rate']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing fileerror: {str(e)}\")\n",
    "                    if 'df' in locals():\n",
    "                        print(f\"File column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\nProcessing Llama {model_size} model\")\n",
    "    results = analyze_llama_folder(folder, valid_icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'char_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} å­ç¬¦éè¯¯ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())\n",
    "\n",
    "# ICD code\n",
    "def collect_valid_codes(folders):\n",
    "    valid_codes = set()\n",
    "    for folder in folders:\n",
    "        for folder_name in os.listdir(folder):\n",
    "            folder_path = os.path.join(folder, folder_name)\n",
    "            \n",
    "            if os.path.isdir(folder_path):\n",
    "                prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "                if os.path.exists(prediction_file):\n",
    "                    try:\n",
    "                        df = load_jsonl(prediction_file)\n",
    "                        for _, row in df.iterrows():\n",
    "                            codes = convert_to_array(row['label'])\n",
    "                            valid_codes.update(codes)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Processing fileerror: {str(e)}\")\n",
    "    return valid_codes\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/enhance\",\n",
    "]\n",
    "\n",
    "# ICD code\n",
    "print(\"Collecting valid ICD codes...\")\n",
    "valid_icd_codes = collect_valid_codes(llama_folders)\n",
    "print(f\"Collected {len(valid_icd_codes)} valid ICD codes\")\n",
    "\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\nProcessing Llama {model_size} model\")\n",
    "    results = analyze_llama_folder(folder, valid_icd_codes)\n",
    "    \n",
    "    # and save\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    output_file = f'char_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} å­ç¬¦éè¯¯ç»æ ===\")\n",
    "    print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08b299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"[Translated]JSONL[Translated]\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_icd_codes(text):\n",
    "    \"\"\"[Translated]ICD[Translated]\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    matches = re.findall(r'[A-Z]\\d{2}\\.?\\d*[A-Z]?', str(text))\n",
    "    return [match.replace('.', '') for match in matches]\n",
    "\n",
    "def get_code_count(text):\n",
    "    \"\"\"[Translated]\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith('['):\n",
    "            cleaned = text.strip('[]').replace(\"'\", \"\").replace('\"', '')\n",
    "            return len([x for x in cleaned.split(',') if x.strip()])\n",
    "        elif re.match(r'^[A-Z]\\d{2}\\.?\\d*[A-Z]?$', text.strip()):\n",
    "            return 1\n",
    "        else:\n",
    "            codes = extract_icd_codes(text)\n",
    "            return len(codes)\n",
    "    return 0\n",
    "\n",
    "def check_counts_llama(path):\n",
    "    \"\"\"[Translated]LLAMA[Translated]\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for folder_name in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            prediction_file = os.path.join(folder_path, \"generated_predictions.jsonl\")\n",
    "            if os.path.exists(prediction_file):\n",
    "                df = load_jsonl(prediction_file)\n",
    "                total = len(df)\n",
    "                \n",
    "                is_mimic = 'mimic' in folder_name.lower()\n",
    "                \n",
    "                wrong_count = 0\n",
    "                for _, row in df.iterrows():\n",
    "                    label_count = get_code_count(row['label'])\n",
    "                    \n",
    "                    if is_mimic:\n",
    "                        pred_codes = extract_icd_codes(row['predict'])\n",
    "                        pred_count = len(pred_codes)\n",
    "                    else:\n",
    "                        pred_count = get_code_count(row['predict'])\n",
    "                    \n",
    "                    if label_count != pred_count:\n",
    "                        wrong_count += 1\n",
    "                            print(f\"\\nExample - {folder_name}:\")\n",
    "                            print(f\"Label ({label_count}): {row['label']}\")\n",
    "                            print(f\"Predict ({pred_count}): {row['predict']}\")\n",
    "                            if is_mimic or not row['predict'].startswith('['):\n",
    "                                extracted_codes = extract_icd_codes(row['predict'])\n",
    "                                print(f\"Extracted codes: {extracted_codes}\")\n",
    "                \n",
    "                error_rate = wrong_count/total if total > 0 else 0\n",
    "                print(f\"{folder_name}: {wrong_count}/{total} = {error_rate:.4f}\")\n",
    "                \n",
    "                results[folder_name] = {\n",
    "                    'total_samples': total,\n",
    "                    'wrong_count': wrong_count,\n",
    "                    'error_rate': error_rate\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "llama_folders = [\n",
    "    \"/Users/houzhen/research/LLMCoder/code/llama_auto/enhance\",\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "for folder in llama_folders:\n",
    "    model_size = folder.split('/')[-1]\n",
    "    print(f\"\\n=== Llama {model_size} model ===\")\n",
    "    results = check_counts_llama(folder)\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    \n",
    "    output_file = f'count_errors_llama_{model_size}.csv'\n",
    "    results_df.round(4).to_csv(output_file)\n",
    "    \n",
    "    print(f\"\\n=== Llama {model_size} Summary of results ===\")\n",
    "    print(results_df.round(4).to_string())\n",
    "    \n",
    "    all_results[model_size] = results\n",
    "\n",
    "all_results_df = pd.concat([pd.DataFrame.from_dict(res, orient='index').assign(model=size) \n",
    "                          for size, res in all_results.items()])\n",
    "all_results_df.to_csv('count_errors_llama_all.csv')\n",
    "\n",
    "print(\"\\n=== ææmodelæ±æ» ===\")\n",
    "for size, res in all_results.items():\n",
    "    print(f\"\\n{size} modelå¹³åError rate: {pd.DataFrame(res).loc['error_rate'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fc7685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264fa75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b00803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bb139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2eeddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6977844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "error_types = ['Nonexistent Code Generation', 'Level Errors', 'Character Errors', 'Quantity Errors']\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "plt.xlabel('Error Types', fontsize=14)\n",
    "plt.ylabel('Total Error Counts', fontsize=14)\n",
    "\n",
    "plt.title('Total Error Counts by Error Type and Training Stage', fontsize=16)\n",
    "\n",
    "for i in range(len(error_types)):\n",
    "    plt.text(x[i] - bar_width, target[i], f'{target[i]:,}', ha='center', va='bottom', fontsize=10)\n",
    "    plt.text(x[i], pretrain[i], f'{pretrain[i]:,}', ha='center', va='bottom', fontsize=10)\n",
    "    plt.text(x[i] + bar_width, train[i], f'{train[i]:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b60e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_1b = [33642, 9963, 8415, 20009]\n",
    "data_3b = [23178, 4715, 7484, 19697]\n",
    "data_8b = [22450, 4045, 8512, 19949]\n",
    "data_target = [1000, 1000, 1000, 1000]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.bar(index, data_target, bar_width, label='Target Fine-tuning', color=target_color)\n",
    "ax.bar(index + 1 * bar_width, data_1b, bar_width, label='1B Pre-train', color=pre_train_colors[0])\n",
    "ax.bar(index + 2 * bar_width, data_3b, bar_width, label='3B Pre-train', color=pre_train_colors[1])\n",
    "ax.bar(index + 3 * bar_width, data_8b, bar_width, label='8B Pre-train', color=pre_train_colors[2])\n",
    "ax.bar(index + 4 * bar_width, [x * 3 for x in data_1b], bar_width, label='1B Train', color=train_colors[0])\n",
    "ax.bar(index + 5 * bar_width, [x * 3 for x in data_3b], bar_width, label='3B Train', color=train_colors[1])\n",
    "ax.bar(index + 6 * bar_width, [x * 3 for x in data_8b], bar_width, label='8B Train', color=train_colors[2])\n",
    "\n",
    "ax.set_xlabel('Error Type')\n",
    "ax.set_xticklabels(['Non-existence Errors', 'Hierarchy-Level Errors', 'Quantity Mismatches', 'Character Errors'])\n",
    "\n",
    "ax.set_ylabel('Total Errors')\n",
    "\n",
    "\n",
    "ax.yaxis.grid(True, linestyle='--', which='major', color='gray', alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6007892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f59801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a032f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
